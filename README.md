# Neural Machine MultiLanguage Translation System

This project implements a **Multilanguage Neural Machine Translation (NMT)** system using **Sequence-to-Sequence (Seq2Seq)** models with **attention mechanisms**, built in **Python** using **TensorFlow and NLP libraries**.

##  Project Description

The system can **translate sentences between multiple languages** (e.g., English â‡„ French, German, Spanish, etc.) using deep learning. It uses an **encoder-decoder architecture** enhanced with an **attention layer** to better focus on relevant parts of the input sequence while translating.

## Features
-  Supports multiple language pairs (trainable)
-  Encoder-Decoder architecture using LSTM
-  Attention mechanism for improved context
-  Inference mode for sentence prediction
-  High translation accuracy with BLEU score evaluation

##  Tech Stack

- Python
- TensorFlow / Keras
- Numpy / Pandas
- Matplotlib / Seaborn
- Natural Language Toolkit (NLTK or SpaCy)
